{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       \n",
    "os.chdir('/workspace/Linux/Linux_project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "                        H: 32                            \n",
      "                        W: 32                            \n",
      "               batch_size: 8                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "             dataset_mode: cifar10                       \n",
      "                    debug: False                         \n",
      "            deterministic: False                         \n",
      "                  dropout: True                          \t[default: False]\n",
      "              epoch_count: 1                             \n",
      "                  gpu_ids: 0                             \t[default: 1]\n",
      "                 img_freq: 40                            \t[default: 1]\n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "               load_epoch: last                          \n",
      "                loss_freq: 30                            \t[default: 1]\n",
      "                     lr_G: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: 1000                          \t[default: inf]\n",
      "                    model: classification                \n",
      "                 n_blocks: 6                             \n",
      "           n_downsampling: 1                             \n",
      "                 n_epochs: 20                            \t[default: 1]\n",
      "           n_epochs_decay: 5                             \t[default: 1]\n",
      "                    n_pic: 3                             \n",
      "                     name: test                          \n",
      "                      ngf: 32                            \n",
      "          no_data_shuffle: False                         \n",
      "             non_blocking: False                         \n",
      "                     norm: batch                         \n",
      "              num_workers: 4                             \n",
      "                output_nc: 10                            \n",
      "                    phase: train                         \n",
      "                  pin_mem: False                         \n",
      "          save_epoch_freq: 5                             \t[default: 10]\n",
      "                  use_cpu: False                         \n",
      "         use_dataparallel: False                         \n",
      "                w_decay_G: 0.0001                        \n",
      "----------------- End -------------------\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10 was created\n",
      "The number of training images = 1000\n",
      "\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10 was created\n",
      "The number of val images = 1000\n",
      "\n",
      "Runing on cuda:0\n",
      "initialize network with normal\n",
      "model [ClassificationModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network netG] Total number of parameters : 2.121 M\n",
      "-----------------------------------------------\n",
      "\n",
      "Training...\n",
      "End of training on epoch 1 / 25 \t Time Taken: 2.50 sec\n",
      "Validation...\n",
      "End of validation on epoch 1  \t Time Taken: 0.71 sec\n",
      "Validation loss 2.03866854763031\n",
      "\n",
      "Training...\n",
      "End of training on epoch 2 / 25 \t Time Taken: 2.26 sec\n",
      "Validation...\n",
      "End of validation on epoch 2  \t Time Taken: 0.67 sec\n",
      "Validation loss 1.8953608093261718\n",
      "\n",
      "Training...\n",
      "End of training on epoch 3 / 25 \t Time Taken: 2.26 sec\n",
      "Validation...\n",
      "End of validation on epoch 3  \t Time Taken: 0.71 sec\n",
      "Validation loss 1.7755929689407348\n",
      "\n",
      "Training...\n",
      "End of training on epoch 4 / 25 \t Time Taken: 2.32 sec\n",
      "Validation...\n",
      "End of validation on epoch 4  \t Time Taken: 0.68 sec\n",
      "Validation loss 1.6923920936584473\n",
      "\n",
      "Training...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 54, in <module>\n",
      "    for i, data in enumerate(dataset):\n",
      "  File \"/workspace/Linux/Linux_project/dataloader/__init__.py\", line 42, in __iter__\n",
      "    for i, data in enumerate(self.dataloader):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 279, in __iter__\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 746, in __init__\n",
      "    self._try_put_index()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 861, in _try_put_index\n",
      "    index = self._next_index()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 339, in _next_index\n",
      "    return next(self._sampler_iter)  # may raise StopIteration\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/sampler.py\", line 200, in __iter__\n",
      "    for idx in self.sampler:\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/sampler.py\", line 107, in __iter__\n",
      "    return iter(torch.randperm(n).tolist())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --name test\\\n",
    "--gpu_ids 0\\\n",
    "--batch_size 8\\\n",
    "--dropout\\\n",
    "--lr_G 0.0002\\\n",
    "--img_freq 40\\\n",
    "--loss_freq 30\\\n",
    "--save_epoch_freq 5\\\n",
    "--n_epochs 20\\\n",
    "--n_epochs_decay 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
